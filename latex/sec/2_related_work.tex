\section{Related work}

\subsection{GPT-4o}
\ 

GPT-4o and GPT-4o \cite{chatgpt}Mini are advanced natural language processing models provided by OpenAI, offering powerful capabilities in text comprehension and generation. They can efficiently handle complex tasks such as text generation, language translation, and conversation. These models \cite{yuanjibao} emphasize the generally low quality of existing plagiarism text datasets, which are characterized by uneven data distribution, limited corpus size, and a lack of diversity in plagiarized texts. These challenges not only constrain the training effectiveness of plagiarism detection models but also limit their ability to handle complex plagiarism scenarios. To address these issues, this study utilizes GPT-4 to generate three types of data: non-plagiarized texts, implicit plagiarism texts, and explicit plagiarism texts. This generation strategy, by simulating various types of plagiarism behaviors, significantly enhances the diversity and quality of the dataset.

\subsection{FIASS}
\

FAISS is an open-source library developed by Facebook, specializing in fast and efficient similarity search and clustering. It is particularly well-suited for handling large dense vector datasets, such as text or image features extracted from deep learning models. In text similarity tasks, FAISS offers various indexing algorithms (such as inner product and Euclidean distance) and supports GPU acceleration, significantly improving search efficiency.

\subsection{SentenceTransformer}
\

SentenceTransformer is a Python library designed for converting sentences or paragraphs into embedding vectors, based on the Transformer architecture. By utilizing pre-trained models (such as BERT, RoBERTa, or MPNet), it generates semantically rich vector representations, facilitating subsequent similarity computations or clustering analyses.

\subsection{NLTK}
\

NLTK tokenizer is part of the Python natural language processing library NLTK (Natural Language Toolkit), used to split text into smaller units such as words or sentences. It provides a variety of efficient tokenization tools suitable for word tokenization, sentence tokenization, and other applications. The simplicity, ease of use, and high accuracy of the NLTK tokenizer make it an indispensable tool in text preprocessing, especially in fields such as natural language processing, information retrieval, and machine learning.